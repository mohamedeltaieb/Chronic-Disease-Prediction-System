{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F9ei2FQuU5-S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
        "from skimage.filters import gabor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"fatemehmehrparvar/lung-disease\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y85UKc3U768",
        "outputId": "814a0e3a-b28d-4069-ede3-10778b29e890"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/fatemehmehrparvar/lung-disease?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34.9M/34.9M [00:00<00:00, 51.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/fatemehmehrparvar/lung-disease/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder, label, augment=False):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        # Indent the following lines to be part of the for loop\n",
        "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            # Preprocessing\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "            img = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
        "            img = cv2.equalizeHist(img)  # Histogram equalization\n",
        "\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "            if augment:\n",
        "                # More sophisticated augmentation\n",
        "                augmentations = [\n",
        "                    cv2.flip(img, 1),  # Horizontal flip\n",
        "                    cv2.flip(img, 0),  # Vertical flip\n",
        "                    cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
        "                    cv2.GaussianBlur(img, (5,5), 0.5),\n",
        "                    # Add the beta parameter (weight for the second image) and gamma\n",
        "                    cv2.addWeighted(img, 0.8, cv2.GaussianBlur(img, (5,5), 0.2, 0), 0.2, 0)  # Mixup-like\n",
        "                ]\n",
        "\n",
        "                for aug_img in augmentations:\n",
        "                    images.append(aug_img)\n",
        "                    labels.append(label)\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "DxKdY8NKU-Fa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_color_histogram(images, bins=32):\n",
        "    \"\"\"Extract color histogram features\"\"\"\n",
        "    features_list = []\n",
        "\n",
        "    for img in images:\n",
        "        if len(img.shape) == 2:  # Grayscale image\n",
        "            hist = cv2.calcHist([img], [0], None, [bins], [0, 256])\n",
        "            hist = hist.flatten()\n",
        "        else:  # Color image\n",
        "            # Compute histogram for each channel\n",
        "            hist_r = cv2.calcHist([img], [0], None, [bins], [0, 256])\n",
        "            hist_g = cv2.calcHist([img], [1], None, [bins], [0, 256])\n",
        "            hist_b = cv2.calcHist([img], [2], None, [bins], [0, 256])\n",
        "\n",
        "            # Concatenate and normalize\n",
        "            hist = np.concatenate([hist_r, hist_g, hist_b]).flatten()\n",
        "\n",
        "        # Normalize histogram\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        features_list.append(hist)\n",
        "\n",
        "    features=np.array(features_list)\n",
        "    features = np.nan_to_num(features)\n",
        "\n",
        "    # Dimensionality reduction\n",
        "    pca = PCA(n_components=0.99)\n",
        "    # Return both the transformed features and the fitted pca object\n",
        "    return pca.fit_transform(features), pca"
      ],
      "metadata": {
        "id": "02RcFznyVA-f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "base_dir = Path(path) / 'Lung X-Ray Image' / 'Lung X-Ray Image'\n",
        "categories = ['Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
        "X, y = [], []\n"
      ],
      "metadata": {
        "id": "GAETJM4aVEGS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 200\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "for category in categories:\n",
        "    folder = os.path.join(base_dir, category)\n",
        "    augment = True  # Augment all classes\n",
        "    images, labels = load_images_from_folder(folder, category, augment=augment)\n",
        "    X.extend(images)\n",
        "    y.extend(labels)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "L9Xw5telVVsT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features\n",
        "print(\"Extracting combined features...\")\n",
        "X_features, feature_pca = extract_color_histogram(X)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAziA2KaVYoS",
        "outputId": "f6c28e62-43ad-4e71-bea3-b243f2d9a12b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting combined features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_features, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")"
      ],
      "metadata": {
        "id": "-3Nw0chlVaXY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "NZyGxuU7VcKG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "rf_model=RandomForestClassifier(bootstrap=False, max_depth=None,\n",
        "                                min_samples_split=5, n_estimators=300)\n",
        "svm_model=SVC(C=10, gamma=0.1, kernel='rbf', probability=True)\n",
        "\n",
        "voting = VotingClassifier(\n",
        "    estimators=[('rf', rf_model), ('svm', svm_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting.fit(X_train_scaled, y_train)\n",
        "y_pred = voting.predict(X_test_scaled)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred, target_names=categories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEKPNLfYVeQn",
        "outputId": "f0c0a5e4-9865-4d68-f8a0-e849fa4cd8d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9691\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   Lung_Opacity       0.98      0.96      0.97      1350\n",
            "         Normal       0.96      0.99      0.97      1500\n",
            "Viral Pneumonia       0.98      0.96      0.97      1320\n",
            "\n",
            "       accuracy                           0.97      4170\n",
            "      macro avg       0.97      0.97      0.97      4170\n",
            "   weighted avg       0.97      0.97      0.97      4170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import joblib\n",
        "# Import drive for Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the base path to your Google Drive\n",
        "drive_path = '/content/drive/MyDrive' # This is the default mount point\n",
        "\n",
        "# Define the directory within your Drive where you want to save the model\n",
        "model_dir_in_drive = os.path.join(drive_path, 'GP', 'Lung Disease')\n",
        "\n",
        "# Ensure the directory exists in Google Drive\n",
        "os.makedirs(model_dir_in_drive, exist_ok=True)\n",
        "\n",
        "# Define the full path to the pickle file\n",
        "pkl_path = os.path.join(model_dir_in_drive, \"voting.pkl\")\n",
        "\n",
        "# Save as a pickle file\n",
        "with open(pkl_path, 'wb') as f:\n",
        "    pickle.dump(voting, f)  # Save the 'voting' model object\n",
        "\n",
        "# After training in your notebook, add:\n",
        "joblib.dump(feature_pca, '/content/drive/MyDrive/GP/Lung Disease/feature_pca.pkl')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/GP/Lung Disease/scaler.pkl')\n",
        "joblib.dump(label_encoder, '/content/drive/MyDrive/GP/Lung Disease/label_encoder.pkl')\n",
        "\n",
        "print(\"Model saved successfully to:\", pkl_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVO9jhSLVqXp",
        "outputId": "b8383212-96f1-450f-ede3-f85580a6d717"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model saved successfully to: /content/drive/MyDrive/GP/Lung Disease/voting.pkl\n"
          ]
        }
      ]
    }
  ]
}