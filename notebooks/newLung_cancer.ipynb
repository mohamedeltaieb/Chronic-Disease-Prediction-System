{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "moa-gfUMWuI6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
        "from skimage.filters import gabor\n",
        "from pathlib import Path\n",
        "import kagglehub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from Kaggle\n",
        "dataset_path = kagglehub.dataset_download(\"andrewmvd/lung-and-colon-cancer-histopathological-images\")\n",
        "dataset_dir = os.path.join(dataset_path, \"lung_colon_image_set\", \"lung_image_sets\")\n",
        "\n",
        "# Set base directory for local processing\n",
        "base_dir = os.path.join(dataset_path, \"lung_colon_image_set\", \"lung_image_sets\")"
      ],
      "metadata": {
        "id": "9DJ37LbuW5hy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder, label, augment=False):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        # Indent the following lines to be part of the for loop\n",
        "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            # Preprocessing\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "            img = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
        "            img = cv2.equalizeHist(img)  # Histogram equalization\n",
        "\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "            if augment:\n",
        "                # More sophisticated augmentation\n",
        "                augmentations = [\n",
        "                    cv2.flip(img, 1),  # Horizontal flip\n",
        "                    cv2.flip(img, 0),  # Vertical flip\n",
        "                    cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
        "                    cv2.GaussianBlur(img, (5,5), 0.5),\n",
        "                    # Add the beta parameter (weight for the second image) and gamma\n",
        "                    cv2.addWeighted(img, 0.8, cv2.GaussianBlur(img, (5,5), 0.2, 0), 0.2, 0)  # Mixup-like\n",
        "                ]\n",
        "\n",
        "                for aug_img in augmentations:\n",
        "                    images.append(aug_img)\n",
        "                    labels.append(label)\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "d6xUSiE-W8SO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_color_histogram(images, bins=32):\n",
        "    \"\"\"Extract color histogram features\"\"\"\n",
        "    features_list = []\n",
        "\n",
        "    for img in images:\n",
        "        if len(img.shape) == 2:  # Grayscale image\n",
        "            hist = cv2.calcHist([img], [0], None, [bins], [0, 256])\n",
        "            hist = hist.flatten()\n",
        "        else:  # Color image\n",
        "            # Compute histogram for each channel\n",
        "            hist_r = cv2.calcHist([img], [0], None, [bins], [0, 256])\n",
        "            hist_g = cv2.calcHist([img], [1], None, [bins], [0, 256])\n",
        "            hist_b = cv2.calcHist([img], [2], None, [bins], [0, 256])\n",
        "\n",
        "            # Concatenate and normalize\n",
        "            hist = np.concatenate([hist_r, hist_g, hist_b]).flatten()\n",
        "\n",
        "        # Normalize histogram\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        features_list.append(hist)\n",
        "\n",
        "    features=np.array(features_list)\n",
        "    features = np.nan_to_num(features)\n",
        "\n",
        "    # Dimensionality reduction\n",
        "    pca = PCA(n_components=0.99)\n",
        "    # Return both the transformed features and the fitted pca object\n",
        "    return pca.fit_transform(features), pca"
      ],
      "metadata": {
        "id": "rDh8OP2xXG11"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 200\n",
        "RANDOM_STATE = 42\n",
        "categories = ['lung_aca', 'lung_n', 'lung_scc']\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for category in categories:\n",
        "    folder = os.path.join(base_dir, category)\n",
        "    augment = True  # Augment all classes\n",
        "    images, labels = load_images_from_folder(folder, category, augment=augment)\n",
        "    X.extend(images)\n",
        "    y.extend(labels)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "b8QlTPBkXIoT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features\n",
        "print(\"Extracting combined features...\")\n",
        "X_features, feature_pca = extract_color_histogram(X)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjj4xKn3Xdcr",
        "outputId": "9e1e910d-209e-46fd-ee62-4bd0abc1f165"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting combined features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_features, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")"
      ],
      "metadata": {
        "id": "mfeGQFNLXfSu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "jLMtMNGXXjRh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "rf_model=RandomForestClassifier(bootstrap=False, max_depth=None,\n",
        "                                min_samples_split=5, n_estimators=300)\n",
        "svm_model=SVC(C=10, gamma=0.1, kernel='rbf', probability=True)\n",
        "\n",
        "voting = VotingClassifier(\n",
        "    estimators=[('rf', rf_model), ('svm', svm_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting.fit(X_train_scaled, y_train)\n",
        "y_pred = voting.predict(X_test_scaled)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred, target_names=categories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCezS1LCXk2i",
        "outputId": "46f6db3f-4a9b-4745-a45b-614d00e7a25a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9753\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    lung_aca       0.96      0.96      0.96      6000\n",
            "      lung_n       0.99      0.99      0.99      6000\n",
            "    lung_scc       0.97      0.98      0.98      6000\n",
            "\n",
            "    accuracy                           0.98     18000\n",
            "   macro avg       0.98      0.98      0.98     18000\n",
            "weighted avg       0.98      0.98      0.98     18000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "# Import drive for Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the base path to your Google Drive\n",
        "drive_path = '/content/drive/MyDrive' # This is the default mount point\n",
        "\n",
        "# Define the directory within your Drive where you want to save the model\n",
        "model_dir_in_drive = os.path.join(drive_path, 'GP', 'Lung_cancer')\n",
        "\n",
        "# Ensure the directory exists in Google Drive\n",
        "os.makedirs(model_dir_in_drive, exist_ok=True)\n",
        "\n",
        "# Define the full path to the pickle file\n",
        "pkl_path = os.path.join(model_dir_in_drive, \"voting.pkl\")\n",
        "\n",
        "# Modify the saving code to include all necessary components\n",
        "model_data = {\n",
        "    'pca': feature_pca,\n",
        "    'scaler': scaler\n",
        "}\n",
        "\n",
        "# Save as a pickle file\n",
        "with open(pkl_path, 'wb') as f:\n",
        "    pickle.dump(model_data, f)  # Save the entire pipeline\n",
        "\n",
        "print(\"Model saved successfully to:\", pkl_path)\n",
        "# Save as a pickle file\n",
        "with open(pkl_path, 'wb') as f:\n",
        "    pickle.dump(voting, f)  # Save the 'voting' model object\n",
        "\n",
        "print(\"Model saved successfully to:\", pkl_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkfPSPboXmbj",
        "outputId": "9e30f81f-99e1-4e79-dcef-928c2a25cb5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model saved successfully to: /content/drive/MyDrive/GP/Lung_cancer/voting.pkl\n",
            "Model saved successfully to: /content/drive/MyDrive/GP/Lung_cancer/voting.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Modify the saving code to include all necessary components\n",
        "model_data = {\n",
        "    'pca': feature_pca,\n",
        "    'scaler': scaler,\n",
        "    'voting_model': voting # Include the trained voting model\n",
        "}\n",
        "\n",
        "# Define the full path to the pickle file (using a different name or structure if you want to save multiple things)\n",
        "# Let's save the model data in a separate file\n",
        "model_data_pkl_path = os.path.join(model_dir_in_drive, \"model_components.pkl\")\n",
        "\n",
        "\n",
        "# Save the model data as a pickle file\n",
        "with open(model_data_pkl_path, 'wb') as f:\n",
        "    pickle.dump(model_data, f)  # Save the dictionary containing all components\n",
        "\n",
        "print(\"Model components (PCA, Scaler, Voting Model) saved successfully to:\", model_data_pkl_path)\n",
        "\n",
        "# If you still want to save the voting model separately (though including it in model_data is often sufficient)\n",
        "# you can use a different file name or handle it as needed.\n",
        "# For now, we've included it in the 'model_components.pkl' file.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZykJPZPuXUd",
        "outputId": "58f06141-122b-42de-ce89-0318dbdf001b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model components (PCA, Scaler, Voting Model) saved successfully to: /content/drive/MyDrive/GP/Lung_cancer/model_components.pkl\n"
          ]
        }
      ]
    }
  ]
}